<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    
    <title> - Unofficial Parallel WaveGAN Implementation Demo</title>
    
    <meta name="description" content="Unofficial Parallel WaveGAN (&#43; MelGAN &amp; Multi-band MelGAN) implementation demo This is the demonstration page of UNOFFICIAL Parallel WaveGAN, MelGAN and Multi-band MelGAN implementations.
Github: https://github.com/kan-bayashi/ParallelWaveGAN
Audio samples (English) Here is the comparison in the analysis-synthesis condition using LJSpeech dataset.
Note that we limit the frequency range from 80 to 7600 Hz in Mel spectrogram calculation.
 Groundtruth: Target speech. Parallel WaveGAN (official): Official samples provided in the official demo HP.">
    <meta name="author" content="">
    
    <link href="https://github.com/bejanidze/bejanidze.github.io/an-old-hope.min.css" rel="stylesheet">
    <link href="https://github.com/bejanidze/bejanidze.github.io/style.css" rel="stylesheet">
    
    <meta name="generator" content="Hugo 0.70.0" />
    
    <link rel="alternate" type="application/atom+xml" href="https://github.com/bejanidze/bejanidze.github.io/index.xml" title="Unofficial Parallel WaveGAN Implementation Demo">
    
    
    
    <script>
      function setTheme() {
        const time = new Date();

        const prev = localStorage.getItem('date');
        const date = String(time.getMonth() + 1) + '.' + String(time.getDate());

        const now = time.getTime();
        let sunrise;
        let sunset;

        function setBodyClass() {
          if (now > sunrise && now < sunset) return;
          document.body.classList.add('dark');
        }

        if (date !== prev) {
          fetch('https://api.ipgeolocation.io/astronomy?apiKey=5ed37d85103e4defa5df4c5298ed5215')
            .then(res => res.json())
            .then(data => {
              sunrise = data.sunrise.split(':').map(Number);
              sunset = data.sunset.split(':').map(Number);
            })
            .catch(() => {
              sunrise = [7, 0];
              sunset = [19, 0];
            })
            .finally(() => {
              sunrise = time.setHours(sunrise[0], sunrise[1], 0);
              sunset = time.setHours(sunset[0], sunset[1], 0);
              setBodyClass();
              localStorage.setItem('sunrise', sunrise);
              localStorage.setItem('sunset', sunset);
            });
          localStorage.setItem('date', date);
        } else {
          sunrise = Number(localStorage.getItem('sunrise'));
          sunset = Number(localStorage.getItem('sunset'));
          setBodyClass();
        }
      }
    </script>
  </head>
  <body class="single">
    <script>
      setTheme();
    </script>
    <header class="header">
      <nav class="nav">
        
        <p class="logo"><a href="https://kan-bayashi.github.io/ParallelWaveGAN/">Unofficial Parallel WaveGAN Implementation Demo</a></p>
        
        
      </nav>
    </header>
    <main class="main">


<article class="post-single">
  <header class="post-header">
    <h1 class="post-title"></h1>
    <div class="post-meta">November 5, 2019</div>
  </header>
  <div class="post-content"><h1 id="unofficial-parallel-wavegan--melgan--multi-band-melgan-implementation-demo">Unofficial Parallel WaveGAN (+ MelGAN &amp; Multi-band MelGAN) implementation demo</h1>
<p>This is the demonstration page of <strong>UNOFFICIAL</strong> Parallel WaveGAN, MelGAN and Multi-band MelGAN implementations.</p>
<p>Github: <a href="https://github.com/kan-bayashi/ParallelWaveGAN">https://github.com/kan-bayashi/ParallelWaveGAN</a></p>
<h2 id="audio-samples-english">Audio samples (English)</h2>
<p>Here is the comparison in the analysis-synthesis condition using <a href="https://keithito.com/LJ-Speech-Dataset/">LJSpeech dataset</a>.<br>
Note that we limit the frequency range from 80 to 7600 Hz in Mel spectrogram calculation.</p>
<ul>
<li><strong>Groundtruth</strong>: Target speech.</li>
<li><strong>Parallel WaveGAN (official)</strong>: Official samples provided in <a href="https://r9y9.github.io/demos/projects/icassp2020">the official demo HP</a>.</li>
<li><strong>Parallel WaveGAN (ours)</strong>: Our samples based <a href="https://github.com/kan-bayashi/ParallelWaveGAN/blob/master/egs/ljspeech/voc1/conf/parallel_wavegan.v1.yaml">this config</a>.</li>
<li><strong>MelGAN + STFT-loss (ours)</strong>: Our samples based <a href="https://github.com/kan-bayashi/ParallelWaveGAN/blob/master/egs/ljspeech/voc1/conf/melgan.v3.long.yaml">this config</a>.</li>
<li><strong>FB-MelGAN (ours)</strong>: Our samples based <a href="https://github.com/kan-bayashi/ParallelWaveGAN/blob/master/egs/ljspeech/voc1/conf/full_band_melgan.v1.yaml">this config</a>.</li>
<li><strong>MB-MelGAN (ours)</strong>: Our samples based <a href="https://github.com/kan-bayashi/ParallelWaveGAN/blob/master/egs/ljspeech/voc1/conf/multi_band_melgan.v1.yaml">this config</a>.</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>ParallelWaveGAN (official)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/raw/LJ050-0029.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/r9y9_wavegan/LJ050-0029.wav"/></audio></td>
</tr>
<tr>
<td><strong>ParallelWaveGAN (ours)</strong></td>
<td><strong>MelGAN + STFT-loss (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_wavegan/LJ050-0029.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_melgan/LJ050-0029.wav"/></audio></td>
</tr>
<tr>
<td><strong>FB-MelGAN (ours)</strong></td>
<td><strong>MB-MelGAN (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_fb-melgan/LJ050-0029.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_mb-melgan/LJ050-0029.wav"/></audio></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>ParallelWaveGAN (official)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/raw/LJ050-0030.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/r9y9_wavegan/LJ050-0030.wav"/></audio></td>
</tr>
<tr>
<td><strong>ParallelWaveGAN (ours)</strong></td>
<td><strong>MelGAN + STFT-loss (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_wavegan/LJ050-0030.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_melgan/LJ050-0030.wav"/></audio></td>
</tr>
<tr>
<td><strong>FB-MelGAN (ours)</strong></td>
<td><strong>MB-MelGAN (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_fb-melgan/LJ050-0030.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_mb-melgan/LJ050-0030.wav"/></audio></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>ParallelWaveGAN (official)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/raw/LJ050-0031.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/r9y9_wavegan/LJ050-0031.wav"/></audio></td>
</tr>
<tr>
<td><strong>ParallelWaveGAN (ours)</strong></td>
<td><strong>MelGAN + STFT-loss (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_wavegan/LJ050-0031.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_melgan/LJ050-0031.wav"/></audio></td>
</tr>
<tr>
<td><strong>FB-MelGAN (ours)</strong></td>
<td><strong>MB-MelGAN (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_fb-melgan/LJ050-0031.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_mb-melgan/LJ050-0031.wav"/></audio></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>ParallelWaveGAN (official)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/raw/LJ050-0032.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/r9y9_wavegan/LJ050-0032.wav"/></audio></td>
</tr>
<tr>
<td><strong>ParallelWaveGAN (ours)</strong></td>
<td><strong>MelGAN + STFT-loss (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_wavegan/LJ050-0032.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_melgan/LJ050-0032.wav"/></audio></td>
</tr>
<tr>
<td><strong>FB-MelGAN (ours)</strong></td>
<td><strong>MB-MelGAN (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_fb-melgan/LJ050-0032.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_mb-melgan/LJ050-0032.wav"/></audio></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>ParallelWaveGAN (official)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/raw/LJ050-0033.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/r9y9_wavegan/LJ050-0033.wav"/></audio></td>
</tr>
<tr>
<td><strong>ParallelWaveGAN (ours)</strong></td>
<td><strong>MelGAN + STFT-loss (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_wavegan/LJ050-0033.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_melgan/LJ050-0033.wav"/></audio></td>
</tr>
<tr>
<td><strong>FB-MelGAN (ours)</strong></td>
<td><strong>MB-MelGAN (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_fb-melgan/LJ050-0033.wav"/></audio></td>
<td><audio controls="" ><source src="wav/ljspeech/kan-bayashi_mb-melgan/LJ050-0033.wav"/></audio></td>
</tr>
</tbody>
</table>
<h2 id="audio-samples-japanese">Audio samples (Japanese)</h2>
<p>Audio sampels trained on <a href="https://sites.google.com/site/shinnosuketakamichi/publication/jsut">JSUT dataset</a>.<br>
Note that groundtruth samples are 48 kHz and we downsampled to 24 kHz and we limit the frequency range from 80 to 7600 Hz in Mel spectrogram calculation.</p>
<ul>
<li><strong>Groundtruth</strong>: Target speech.</li>
<li><strong>Parallel WaveGAN (ours)</strong>: Our samples based <a href="https://github.com/kan-bayashi/ParallelWaveGAN/blob/master/egs/jsut/voc1/conf/parallel_wavegan.v1.yaml">this config</a>.</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>ParallelWaveGAN (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/raw/BASIC5000_0001.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/kan-bayashi_wavegan.v1/BASIC5000_0001.wav"/></audio></td>
</tr>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>ParallelWaveGAN (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/raw/BASIC5000_0002.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/kan-bayashi_wavegan.v1/BASIC5000_0002.wav"/></audio></td>
</tr>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>ParallelWaveGAN (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/jsut/raw/BASIC5000_0003.wav"/></audio></td>
<td><audio controls="" ><source src="wav/jsut/kan-bayashi_wavegan.v1/BASIC5000_0003.wav"/></audio></td>
</tr>
</tbody>
</table>
<h2 id="audio-samples-mandarin">Audio samples (Mandarin)</h2>
<p>Audio sampels trained on <a href="https://www.data-baker.com/open_source.html">CSMSC dataset</a>.<br>
Note that groundtruth samples are 48 kHz and we downsampled to 24 kHz and we limit the frequency range from 80 to 7600 Hz in Mel spectrogram calculation.</p>
<ul>
<li><strong>Groundtruth</strong>: Target speech.</li>
<li><strong>Parallel WaveGAN (ours)</strong>: Our samples based <a href="https://github.com/kan-bayashi/ParallelWaveGAN/blob/master/egs/csmsc/voc1/conf/parallel_wavegan.v1.yaml">this config</a>.</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>ParallelWaveGAN (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/csmsc/raw/009901.wav"/></audio></td>
<td><audio controls="" ><source src="wav/csmsc/kan-bayashi_wavegan.v1/009901.wav"/></audio></td>
</tr>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>ParallelWaveGAN (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/csmsc/raw/009902.wav"/></audio></td>
<td><audio controls="" ><source src="wav/csmsc/kan-bayashi_wavegan.v1/009902.wav"/></audio></td>
</tr>
<tr>
<td><strong>Groundtruth</strong></td>
<td><strong>ParallelWaveGAN (ours)</strong></td>
</tr>
<tr>
<td><audio controls="" ><source src="wav/csmsc/raw/009903.wav"/></audio></td>
<td><audio controls="" ><source src="wav/csmsc/kan-bayashi_wavegan.v1/009903.wav"/></audio></td>
</tr>
</tbody>
</table>
<h2 id="references">References</h2>
<ul>
<li><a href="https://arxiv.org/abs/1910.11480">Parallel WaveGAN</a></li>
<li><a href="https://arxiv.org/abs/1910.06711">MelGAN</a></li>
<li><a href="https://r9y9.github.io/demos/projects/icassp2020">Official Parallel WaveGAN demo</a></li>
</ul>
<h2 id="author">Author</h2>
<p>Tomoki Hayashi<br>
e-mail: <a href="mailto:hayashi.tomoki@g.sp.m.is.nagoya-u.ac.jp">hayashi.tomoki@g.sp.m.is.nagoya-u.ac.jp</a></p>
</div>
  
  
  
  
  
</article>

</main>
<footer class="footer">
  <span>&copy; 2020 <a href="https://kan-bayashi.github.io/ParallelWaveGAN/">Unofficial Parallel WaveGAN Implementation Demo</a></span>
  <span>&middot;</span>
  <span>Powered by <a href="https://gohugo.io/" rel="noopener" target="_blank">Hugo️️</a>️</span>
  <span>&middot;</span>
  <span>Theme️ <a href="https://github.com/nanxiaobei/hugo-paper" rel="noopener" target="_blank">Paper</a></span>
</footer>
<script src="https://kan-bayashi.github.io/ParallelWaveGAN/highlight.min.js"></script>
<script>
  hljs.initHighlightingOnLoad();
</script>
</body>
</html>

